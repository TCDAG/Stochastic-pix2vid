{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-RNN Forward Proxy Modeling for CO2 Monitoring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Tensorflow Version:\n",
      "Tensorflow built with CUDA? True\n",
      "Tensorflow version: 2.10.0\n",
      "# GPU available: 1\n",
      "CUDA: 64_112 | cuDNN: 64_8\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from utils2d import *\n",
    "check_tensorflow_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'simulations/poro.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\381792\\AppData\\Local\\anaconda3\\envs\\deep\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_like, mode), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     41\u001b[0m     \u001b[39m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'simulations/poro'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m poro, perm, saturation, pressure \u001b[39m=\u001b[39m load_process_data()\n\u001b[0;32m      3\u001b[0m poro_aug, perm_aug, saturation_aug, pressure_aug \u001b[39m=\u001b[39m augment_data(poro, perm, saturation, pressure)\n\u001b[0;32m      5\u001b[0m plot_dataset(poro_aug, perm_aug, saturation_aug, nrows\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, row_mult\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m,\u001b[39m10\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\381792\\Documents\\CNN-RNN-CO2\\utils2d.py:41\u001b[0m, in \u001b[0;36mload_process_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_process_data\u001b[39m():\n\u001b[0;32m     40\u001b[0m     \u001b[39m# Load data from high-fidelity simulations\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     poro_df       \u001b[39m=\u001b[39m loadmat(\u001b[39m'\u001b[39;49m\u001b[39msimulations/poro\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m'\u001b[39m\u001b[39mporo\u001b[39m\u001b[39m'\u001b[39m]              \u001b[39m#porosity [frac]\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     perm_df       \u001b[39m=\u001b[39m loadmat(\u001b[39m'\u001b[39m\u001b[39msimulations/perm\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mperm\u001b[39m\u001b[39m'\u001b[39m]              \u001b[39m#permeability[mD]\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     saturation_df \u001b[39m=\u001b[39m loadmat(\u001b[39m'\u001b[39m\u001b[39msimulations/saturation\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39msaturation\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m#saturation[frac]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\381792\\AppData\\Local\\anaconda3\\envs\\deep\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:224\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39mLoad MATLAB file.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m variable_names \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mvariable_names\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 224\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    225\u001b[0m     MR, _ \u001b[39m=\u001b[39m mat_reader_factory(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    226\u001b[0m     matfile_dict \u001b[39m=\u001b[39m MR\u001b[39m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[1;32mc:\\Users\\381792\\AppData\\Local\\anaconda3\\envs\\deep\\lib\\contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[0;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\381792\\AppData\\Local\\anaconda3\\envs\\deep\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m@contextmanager\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     f, opened \u001b[39m=\u001b[39m _open_file(file_like, appendmat, mode)\n\u001b[0;32m     18\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m         \u001b[39myield\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Users\\381792\\AppData\\Local\\anaconda3\\envs\\deep\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m appendmat \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m file_like\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.mat\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     44\u001b[0m         file_like \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.mat\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_like, mode), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[0;32m     48\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mReader needs file name or open file-like object\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     49\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'simulations/poro.mat'"
     ]
    }
   ],
   "source": [
    "poro, perm, saturation, pressure = load_process_data()\n",
    "\n",
    "poro_aug, perm_aug, saturation_aug, pressure_aug = augment_data(poro, perm, saturation, pressure)\n",
    "\n",
    "plot_dataset(poro_aug, perm_aug, saturation_aug, nrows=6, row_mult=100, figsize=(16,10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the data to be $\\in[0,1]$; this is known as Min-Max Normalization. This improves the prediction performance of the proxy model given the properties of the activation functions and optimizers in the deep learning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalize predicted saturation values ~ [0,1]\n",
    "perm_min = perm_aug.min(axis=(1,2), keepdims=True)\n",
    "perm_max = perm_aug.max(axis=(1,2), keepdims=True)\n",
    "perm_processed = (perm_aug - perm_min)/(perm_max-perm_min)\n",
    "\n",
    "sat_min = saturation_aug.min(axis=(1,2), keepdims=True)\n",
    "sat_max = saturation_aug.max(axis=(1,2), keepdims=True)\n",
    "sat_processed = (saturation_aug - sat_min)/(sat_max-sat_min)\n",
    "\n",
    "print('Processed Permeability shape: {}'.format(perm_processed.shape))\n",
    "print('Processed Saturation shape:   {}'.format(sat_processed.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform train/test split by randomly generating a set of indices that will be assigned to the training set and the remainder to the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate train-test indices\n",
    "split_perc = (2/3)\n",
    "train_size = int(np.ceil(N_real*2 * split_perc))\n",
    "test_size  = int(np.floor(N_real*2 * (1-split_perc)))\n",
    "\n",
    "train_idx = np.random.choice(N_real*2, size=train_size, replace=False)\n",
    "test_idx  = np.setdiff1d(np.arange(N_real*2), train_idx)\n",
    "\n",
    "# Train/Test split\n",
    "X_train = np.expand_dims(perm_processed[train_idx,:,:], axis=-1)\n",
    "X_test  = np.expand_dims(perm_processed[test_idx,:,:],  axis=-1)\n",
    "y_train = np.expand_dims(sat_processed[train_idx,:,:,:], axis=-1)\n",
    "y_test  = np.expand_dims(sat_processed[test_idx,:,:,:],  axis=-1)\n",
    "\n",
    "print('X_train shape: {} | y_train shape: {}'.format(X_train.shape, y_train.shape))\n",
    "print('X_test  shape: {} | y_test  shape: {}'.format(X_test.shape,  y_test.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the distribution of mean permeability and mean end-state saturation for the training and testing datasets. This is a measure to ensure that the training set is representative of the testing, and that no induced bias will be introduced in training so that the model can generalize well to the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Train/Test distributions (mean, flattened)\n",
    "X_train_f = X_train.reshape(train_size, dim*dim)\n",
    "X_test_f  = X_test.reshape(test_size, dim*dim)\n",
    "\n",
    "y_train_f = y_train[:,:,:,-1].reshape(train_size, dim*dim)\n",
    "y_test_f  = y_test[:,:,:,-1].reshape(test_size, dim*dim)\n",
    "\n",
    "plot_histograms(X_train_f, X_test_f, y_train_f, y_test_f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. CNN-RNN Forward Proxy\n",
    "\n",
    "The model is a hybrid CNN-RNN architecture that will learn how to forecast dynamic states from the latent representation of the static reservoir properties (a reduced-order forward model). The architecture is designed as follows:\n",
    "\n",
    "1. Convolution block: dimensionality reduction from high-resolution permeability to a latent space\n",
    "2. Recurrent block: dynamic predictions in latent space\n",
    "3. Deconvolution block: reconstruct high-resolution saturation maps as a time-series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (re)-Set Keras environment\n",
    "keras.backend.clear_session()\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define proxy model by blocks\n",
    "global_reg = 1e-4\n",
    "\n",
    "# Convolutional block (Encoder)\n",
    "def conv_block(filt, inp, kern=(3,3), reg=global_reg):\n",
    "    x = Conv2D(filters=filt, kernel_size=kern, padding='same', activation=LeakyReLU(alpha=0.3))(inp)\n",
    "    x = Conv2D(filters=filt, kernel_size=kern, padding='same', kernel_regularizer=regularizers.l2(reg))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    return x\n",
    "\n",
    "# Recurrent block\n",
    "def rnn_block(units, inp, drop=0.2):\n",
    "    x = Flatten()(inp)\n",
    "    x = RepeatVector(n=125)(x)\n",
    "    x = GRU(units=units, return_sequences=True, dropout=drop)(x)\n",
    "    x = Reshape((5,5,5, x.shape[-1]))(x)\n",
    "    return x\n",
    "\n",
    "# Transpose Convolutional block (Decoder)\n",
    "def convT_block(filt, stride, inp, kern=(3,3,3), reg=global_reg):\n",
    "    x = Conv3DTranspose(filters=filt, kernel_size=kern, padding='same', strides=1,      activation=LeakyReLU(alpha=0.3))(inp)\n",
    "    x = Conv3DTranspose(filters=filt, kernel_size=kern, padding='same', strides=stride, activation=LeakyReLU(alpha=0.3))(x)\n",
    "    x = Conv3DTranspose(filters=filt, kernel_size=kern, padding='same', kernel_regularizer=regularizers.l2(reg))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    return x\n",
    "\n",
    "# Output block\n",
    "def output_block(filt, inp, kern=(3,3,3)):\n",
    "    x = Conv3DTranspose(filters=filt[0], kernel_size=kern, padding='same', activation='sigmoid')(inp)\n",
    "    x = Conv3D(filters=filt[1], kernel_size=kern, padding='same', activation='sigmoid')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN-RNN forward proxy model\n",
    "def make_proxy():\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Input layer\n",
    "    inp = Input(shape=(dim,dim,1))\n",
    "\n",
    "    # Encoder block\n",
    "    x = conv_block(filt=8,  inp=inp)\n",
    "    x = conv_block(filt=16, inp=x)\n",
    "    x = conv_block(filt=32, inp=x)\n",
    "    x = conv_block(filt=64, inp=x)\n",
    "\n",
    "    # Recurrent block\n",
    "    x = rnn_block(units=128, inp=x)\n",
    "\n",
    "    # Decoder block\n",
    "    x = convT_block(filt=64, stride=2, inp=x)\n",
    "    x = convT_block(filt=32, stride=2, inp=x)\n",
    "    x = convT_block(filt=16, stride=3, inp=x)\n",
    "\n",
    "    # Output block\n",
    "    out = output_block(filt=[8,1], inp=x)\n",
    "\n",
    "    proxy_model = Model(inp, out)\n",
    "    return proxy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_proxy()\n",
    "print('Number of parameters: {:,}'.format(model.count_params()))\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(optimizer = opt,\n",
    "                loss    = 'mse',\n",
    "                metrics = ['mse'])\n",
    "\n",
    "# Fit the model\n",
    "start = time()\n",
    "fit = model.fit(X_train, y_train,\n",
    "                    shuffle          = True,\n",
    "                    epochs           = 300,\n",
    "                    validation_split = 0.25,\n",
    "                    batch_size       = 40,\n",
    "                    workers          = 10,\n",
    "                    verbose          = 0)\n",
    "train_time = time()-start\n",
    "print('Training time: {:.2f} minutes'.format(train_time/60))\n",
    "\n",
    "# Visualize training process\n",
    "plot_loss(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "##### Save/Load (pre)trained model #####\n",
    "########################################\n",
    "\n",
    "model.save('model.h5')\n",
    "#model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we visualize the training performance. This includes computing MSE and SSIM metrics for the true training data and model-predicted training data. We also plot in a single image the permeability map (features) and the true and predicted saturation states (targets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict TRAIN dynamic saturation states\n",
    "y_train_hat = model.predict(X_train).squeeze().astype('float64')\n",
    "\n",
    "# MinMax Normalize predicted saturation values ~ [0,1]\n",
    "y_min  = y_train_hat.min(axis=(1,2), keepdims=True)\n",
    "y_max  = y_train_hat.max(axis=(1,2), keepdims=True)\n",
    "y_train_pred = ((y_train_hat - y_min)/(y_max-y_min))\n",
    "\n",
    "# Squeeze the training dataset\n",
    "y_train = y_train.squeeze()\n",
    "\n",
    "# Print shapes\n",
    "print('y_train_pred shape: {}'.format(y_train_pred.shape))\n",
    "print('y_train shape:      {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute error metrics for training data\n",
    "mse_train  = mean_squared_error(y_train, y_train_pred)\n",
    "ssim_train = structural_similarity(y_train, y_train_pred)\n",
    "print('MSE: {:.3f} | MSSIM: {:.3f}'.format(mse_train, ssim_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also visualize the testing performance. We compute the MSE and SSIM metrics for the true testing data and model-predicted testing data. Lastly, we plot in a single image the permeability maps (features) and the true and predicted saturation states (targets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare true vs. training saturations for a set of permeability realizations\n",
    "compare_results_plot(X_train, y_train, y_train_pred, nrows=4, row_mult=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict TEST dynamic saturation states\n",
    "y_test_hat = model.predict(X_test).squeeze().astype('float64')\n",
    "\n",
    "# MinMax Normalize predicted saturation values ~ [0,1]\n",
    "y_min  = y_test_hat.min(axis=(1,2), keepdims=True)\n",
    "y_max  = y_test_hat.max(axis=(1,2), keepdims=True)\n",
    "y_test_pred = ((y_test_hat - y_min)/(y_max-y_min))\n",
    "\n",
    "# Squeeze the testing data\n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "# Print shapes\n",
    "print('y_test_pred shape: {}'.format(y_test_pred.shape))\n",
    "print('y_test shape:      {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute error metrics for testing data\n",
    "mse  = mean_squared_error(y_test, y_test_pred)\n",
    "ssim = structural_similarity(y_test, y_test_pred)\n",
    "print('MSE: {:.3f} | MSSIM: {:.3f}'.format(mse, ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare true vs. testing predicted saturations for a set of permeability realizations\n",
    "compare_results_plot(X_test, y_test, y_test_pred, nrows=4, row_mult=25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
