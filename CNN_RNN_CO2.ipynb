{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-RNN Forward Proxy Modeling for CO2 Monitoring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils2d import *\n",
    "check_tensorflow_gpu()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 12,
>>>>>>> 7906796cce57cd2584b3887c71c8e445750f702a
   "metadata": {},
   "outputs": [],
   "source": [
    "facies, poro, logperm, wells, states = {}, {}, {}, {}, {}\n",
    "dim = 128\n",
    "pressure = np.zeros((1000,50,dim*dim))\n",
    "saturation = np.zeros((1000,50,dim*dim))\n",
    "\n",
    "for i in range(100):\n",
    "    facies[i]  = loadmat('simulations2D/facies/facies{}'.format(i))['facies']\n",
    "    poro[i]    = loadmat('simulations2D/porosity/poro{}.mat'.format(i))['poro']\n",
    "    logperm[i] = loadmat('simulations2D/permeability/logperm{}.mat'.format(i))['logperm']\n",
    "    wells[i]   = loadmat('simulations2D/wells/wells{}.mat'.format(i))['var']-1\n",
    "    states[i]  = loadmat('simulations2D/states/states{}.mat'.format(i), simplify_cells=True)['var']\n",
    "    for k in range(50):\n",
    "        pressure[i,k] = states[i][k]['pressure'] / 6894.76 #MPa to psia\n",
    "        saturation[i,k] = states[i][k]['s'][:,1]\n",
    "timestamps = loadmat('simulations2D/timestamps.mat')['timestamps'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dynamic(realization):\n",
    "    plt.figure(figsize=(25,10))\n",
    "    plt.subplot(4,14,1); plt.imshow(facies[realization].reshape(128,128), 'viridis'); plt.xticks([]); plt.yticks([]); plt.title('Facies {}'.format(realization)); plt.scatter(wells[realization][:,0], wells[realization][:,1], c='w', marker='d', s=20)\n",
    "    plt.subplot(4,14,2); plt.imshow(poro[realization].reshape(128,128), 'jet'); plt.xticks([]); plt.yticks([]); plt.title('Orig. $\\phi$ {}'.format(realization)); plt.scatter(wells[realization][:,0], wells[realization][:,1], c='w', marker='d', s=20)\n",
    "    plt.subplot(4,14,3); plt.imshow((facies[realization]*poro[realization]).reshape(128,128), 'jet'); plt.xticks([]); plt.yticks([]); plt.title('Fluvial $\\phi$ {}'.format(realization)); plt.scatter(wells[realization][:,0], wells[realization][:,1], c='w', marker='d', s=20)\n",
    "\n",
    "    plt.subplot(4,14,4); plt.imshow(logperm[realization].reshape(128,128), 'jet'); plt.xticks([]); plt.yticks([]); plt.title('Orig. $k$ {}'.format(realization)); plt.scatter(wells[realization][:,0], wells[realization][:,1], c='w', marker='d', s=20)\n",
    "    plt.subplot(4,14,5); plt.imshow((facies[realization]*logperm[realization]).reshape(128,128), 'jet'); plt.xticks([]); plt.yticks([]); plt.title('Fluvial $k$ {}'.format(realization)); plt.scatter(wells[realization][:,0], wells[realization][:,1], c='w', marker='d', s=20)\n",
    "\n",
    "    for k in range(50):\n",
    "        plt.subplot(4,14,k+6)\n",
    "        plt.imshow(saturation[realization,k].reshape(128,128), 'jet')\n",
    "        plt.scatter(wells[realization][:,0], wells[realization][:,1], c='w', marker='d', s=20)\n",
    "        plt.title('t={:.2e} yr'.format(timestamps[k]))\n",
    "        plt.xticks([]); plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poro, perm, saturation, pressure = load_process_data()\n",
    "\n",
    "poro_aug, perm_aug, saturation_aug, pressure_aug = augment_data(poro, perm, saturation, pressure)\n",
    "\n",
    "plot_dataset(poro_aug, perm_aug, saturation_aug, nrows=6, row_mult=100, figsize=(16,10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the data to be $\\in[0,1]$; this is known as Min-Max Normalization. This improves the prediction performance of the proxy model given the properties of the activation functions and optimizers in the deep learning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalize predicted saturation values ~ [0,1]\n",
    "perm_min = perm_aug.min(axis=(1,2), keepdims=True)\n",
    "perm_max = perm_aug.max(axis=(1,2), keepdims=True)\n",
    "perm_processed = (perm_aug - perm_min)/(perm_max-perm_min)\n",
    "\n",
    "sat_min = saturation_aug.min(axis=(1,2), keepdims=True)\n",
    "sat_max = saturation_aug.max(axis=(1,2), keepdims=True)\n",
    "sat_processed = (saturation_aug - sat_min)/(sat_max-sat_min)\n",
    "\n",
    "print('Processed Permeability shape: {}'.format(perm_processed.shape))\n",
    "print('Processed Saturation shape:   {}'.format(sat_processed.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform train/test split by randomly generating a set of indices that will be assigned to the training set and the remainder to the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly generate train-test indices\n",
    "split_perc = (2/3)\n",
    "train_size = int(np.ceil(N_real*2 * split_perc))\n",
    "test_size  = int(np.floor(N_real*2 * (1-split_perc)))\n",
    "\n",
    "train_idx = np.random.choice(N_real*2, size=train_size, replace=False)\n",
    "test_idx  = np.setdiff1d(np.arange(N_real*2), train_idx)\n",
    "\n",
    "# Train/Test split\n",
    "X_train = np.expand_dims(perm_processed[train_idx,:,:], axis=-1)\n",
    "X_test  = np.expand_dims(perm_processed[test_idx,:,:],  axis=-1)\n",
    "y_train = np.expand_dims(sat_processed[train_idx,:,:,:], axis=-1)\n",
    "y_test  = np.expand_dims(sat_processed[test_idx,:,:,:],  axis=-1)\n",
    "\n",
    "print('X_train shape: {} | y_train shape: {}'.format(X_train.shape, y_train.shape))\n",
    "print('X_test  shape: {} | y_test  shape: {}'.format(X_test.shape,  y_test.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the distribution of mean permeability and mean end-state saturation for the training and testing datasets. This is a measure to ensure that the training set is representative of the testing, and that no induced bias will be introduced in training so that the model can generalize well to the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Train/Test distributions (mean, flattened)\n",
    "X_train_f = X_train.reshape(train_size, dim*dim)\n",
    "X_test_f  = X_test.reshape(test_size, dim*dim)\n",
    "\n",
    "y_train_f = y_train[:,:,:,-1].reshape(train_size, dim*dim)\n",
    "y_test_f  = y_test[:,:,:,-1].reshape(test_size, dim*dim)\n",
    "\n",
    "plot_histograms(X_train_f, X_test_f, y_train_f, y_test_f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. CNN-RNN Forward Proxy\n",
    "\n",
    "The model is a hybrid CNN-RNN architecture that will learn how to forecast dynamic states from the latent representation of the static reservoir properties (a reduced-order forward model). The architecture is designed as follows:\n",
    "\n",
    "1. Convolution block: dimensionality reduction from high-resolution permeability to a latent space\n",
    "2. Recurrent block: dynamic predictions in latent space\n",
    "3. Deconvolution block: reconstruct high-resolution saturation maps as a time-series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (re)-Set Keras environment\n",
    "keras.backend.clear_session()\n",
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define proxy model by blocks\n",
    "global_reg = 1e-4\n",
    "\n",
    "# Convolutional block (Encoder)\n",
    "def conv_block(filt, inp, kern=(3,3), reg=global_reg):\n",
    "    x = Conv2D(filters=filt, kernel_size=kern, padding='same', activation=LeakyReLU(alpha=0.3))(inp)\n",
    "    x = Conv2D(filters=filt, kernel_size=kern, padding='same', kernel_regularizer=regularizers.l2(reg))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    return x\n",
    "\n",
    "# Recurrent block\n",
    "def rnn_block(units, inp, drop=0.2):\n",
    "    x = Flatten()(inp)\n",
    "    x = RepeatVector(n=125)(x)\n",
    "    x = GRU(units=units, return_sequences=True, dropout=drop)(x)\n",
    "    x = Reshape((5,5,5, x.shape[-1]))(x)\n",
    "    return x\n",
    "\n",
    "# Transpose Convolutional block (Decoder)\n",
    "def convT_block(filt, stride, inp, kern=(3,3,3), reg=global_reg):\n",
    "    x = Conv3DTranspose(filters=filt, kernel_size=kern, padding='same', strides=1,      activation=LeakyReLU(alpha=0.3))(inp)\n",
    "    x = Conv3DTranspose(filters=filt, kernel_size=kern, padding='same', strides=stride, activation=LeakyReLU(alpha=0.3))(x)\n",
    "    x = Conv3DTranspose(filters=filt, kernel_size=kern, padding='same', kernel_regularizer=regularizers.l2(reg))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    return x\n",
    "\n",
    "# Output block\n",
    "def output_block(filt, inp, kern=(3,3,3)):\n",
    "    x = Conv3DTranspose(filters=filt[0], kernel_size=kern, padding='same', activation='sigmoid')(inp)\n",
    "    x = Conv3D(filters=filt[1], kernel_size=kern, padding='same', activation='sigmoid')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN-RNN forward proxy model\n",
    "def make_proxy():\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    # Input layer\n",
    "    inp = Input(shape=(dim,dim,1))\n",
    "\n",
    "    # Encoder block\n",
    "    x = conv_block(filt=8,  inp=inp)\n",
    "    x = conv_block(filt=16, inp=x)\n",
    "    x = conv_block(filt=32, inp=x)\n",
    "    x = conv_block(filt=64, inp=x)\n",
    "\n",
    "    # Recurrent block\n",
    "    x = rnn_block(units=128, inp=x)\n",
    "\n",
    "    # Decoder block\n",
    "    x = convT_block(filt=64, stride=2, inp=x)\n",
    "    x = convT_block(filt=32, stride=2, inp=x)\n",
    "    x = convT_block(filt=16, stride=3, inp=x)\n",
    "\n",
    "    # Output block\n",
    "    out = output_block(filt=[8,1], inp=x)\n",
    "\n",
    "    proxy_model = Model(inp, out)\n",
    "    return proxy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_proxy()\n",
    "print('Number of parameters: {:,}'.format(model.count_params()))\n",
    "#model.summary()\n",
    "#tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(optimizer = opt,\n",
    "                loss    = 'mse',\n",
    "                metrics = ['mse'])\n",
    "\n",
    "# Fit the model\n",
    "start = time()\n",
    "fit = model.fit(X_train, y_train,\n",
    "                    shuffle          = True,\n",
    "                    epochs           = 300,\n",
    "                    validation_split = 0.25,\n",
    "                    batch_size       = 40,\n",
    "                    workers          = 10,\n",
    "                    verbose          = 0)\n",
    "train_time = time()-start\n",
    "print('Training time: {:.2f} minutes'.format(train_time/60))\n",
    "\n",
    "# Visualize training process\n",
    "plot_loss(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "##### Save/Load (pre)trained model #####\n",
    "########################################\n",
    "\n",
    "model.save('model.h5')\n",
    "#model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we visualize the training performance. This includes computing MSE and SSIM metrics for the true training data and model-predicted training data. We also plot in a single image the permeability map (features) and the true and predicted saturation states (targets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict TRAIN dynamic saturation states\n",
    "y_train_hat = model.predict(X_train).squeeze().astype('float64')\n",
    "\n",
    "# MinMax Normalize predicted saturation values ~ [0,1]\n",
    "y_min  = y_train_hat.min(axis=(1,2), keepdims=True)\n",
    "y_max  = y_train_hat.max(axis=(1,2), keepdims=True)\n",
    "y_train_pred = ((y_train_hat - y_min)/(y_max-y_min))\n",
    "\n",
    "# Squeeze the training dataset\n",
    "y_train = y_train.squeeze()\n",
    "\n",
    "# Print shapes\n",
    "print('y_train_pred shape: {}'.format(y_train_pred.shape))\n",
    "print('y_train shape:      {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute error metrics for training data\n",
    "mse_train  = mean_squared_error(y_train, y_train_pred)\n",
    "ssim_train = structural_similarity(y_train, y_train_pred)\n",
    "print('MSE: {:.3f} | MSSIM: {:.3f}'.format(mse_train, ssim_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also visualize the testing performance. We compute the MSE and SSIM metrics for the true testing data and model-predicted testing data. Lastly, we plot in a single image the permeability maps (features) and the true and predicted saturation states (targets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare true vs. training saturations for a set of permeability realizations\n",
    "compare_results_plot(X_train, y_train, y_train_pred, nrows=4, row_mult=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict TEST dynamic saturation states\n",
    "y_test_hat = model.predict(X_test).squeeze().astype('float64')\n",
    "\n",
    "# MinMax Normalize predicted saturation values ~ [0,1]\n",
    "y_min  = y_test_hat.min(axis=(1,2), keepdims=True)\n",
    "y_max  = y_test_hat.max(axis=(1,2), keepdims=True)\n",
    "y_test_pred = ((y_test_hat - y_min)/(y_max-y_min))\n",
    "\n",
    "# Squeeze the testing data\n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "# Print shapes\n",
    "print('y_test_pred shape: {}'.format(y_test_pred.shape))\n",
    "print('y_test shape:      {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute error metrics for testing data\n",
    "mse  = mean_squared_error(y_test, y_test_pred)\n",
    "ssim = structural_similarity(y_test, y_test_pred)\n",
    "print('MSE: {:.3f} | MSSIM: {:.3f}'.format(mse, ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare true vs. testing predicted saturations for a set of permeability realizations\n",
    "compare_results_plot(X_test, y_test, y_test_pred, nrows=4, row_mult=25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
